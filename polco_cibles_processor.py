#!/usr/bin/env python3
"""
POLCO CIBLES PROCESSOR v3 - VERSION NETTOY√âE
G√©n√®re une analyse des cibles clients propre pour les rapports professionnels.
"""

import os
import logging
from typing import Dict, Any, Optional
from datetime import datetime
from polco_llm_client import get_llm_client

# Configuration
PROJECT_ID = "polcoaigeneration-ved6"
REGION = "us-central1"
MODEL_NAME = "gemini-2.5-flash"

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class PolcoCiblesProcessorV3:
    """Processeur CIBLES v3 pour analyse propre et professionnelle."""
    
    def __init__(self, captation_collection="polco_magasins_captation"):
        self.llm_client = get_llm_client()
        self.captation_collection = captation_collection
    
    def init_vertex_ai(self) -> bool:
        """Initialise Vertex AI."""
        try:
            # Le client LLM est d√©j√† initialis√© dans le constructeur
            logger.info(f"‚úÖ Client LLM standardis√© initialis√© ({MODEL_NAME})")
            return True
        except Exception as e:
            logger.error(f"‚ùå Erreur Vertex AI: {e}")
            return False
    
    def get_captation_results(self, store_id: str) -> str:
        """R√©cup√®re les r√©sultats de captation depuis polco_magasins_enhanced."""
        try:
            from google.cloud import firestore
            db = firestore.Client(project="polcoaigeneration-ved6")
            doc_ref = db.collection(self.captation_collection).document(f"store_{store_id}")
            doc = doc_ref.get()
            
            if not doc.exists:
                logger.warning(f"‚ö†Ô∏è Aucun r√©sultat de captation trouv√© pour store {store_id}")
                return ""
            
            data = doc.to_dict()
            prompts_results = data.get('prompts_results', {})
            
            if len(prompts_results) < 6:
                logger.warning(f"‚ö†Ô∏è Store {store_id}: seulement {len(prompts_results)}/6 prompts disponibles")
                return ""
            
            # FILTRAGE CIBL√â POUR CIBLES : seulement prompts 1, 2 (d√©mographie + comportements)
            relevant_prompts = ['prompt_1', 'prompt_2', 'prompt_7']
            captation_content = "\n=== DONN√âES PERTINENTES POUR CIBLES ===\n"
            
            for prompt_key in relevant_prompts:
                if prompt_key in prompts_results:
                    prompt_data = prompts_results[prompt_key]
                    if prompt_data.get('status') == 'completed' and prompt_data.get('response'):
                        # Limiter chaque prompt √† 20k caract√®res
                        response_text = prompt_data['response']
                        captation_content += f"\n--- {prompt_key.upper()} (D√âMOGRAPHIE & COMPORTEMENTS) ---\n{response_text}\n"
            
            logger.info(f"‚úÖ Store {store_id}: donn√©es cibles r√©cup√©r√©es (prompts 1-2)")
            return captation_content
            
        except Exception as e:
            logger.error(f"‚ùå Erreur r√©cup√©ration captation store {store_id}: {e}")
            return ""
    
    def extract_client_data(self, complete_data: Dict[str, Any]) -> Dict[str, Any]:
        """Extrait les donn√©es clients disponibles."""
        
        store_id = complete_data.get('store_id')
        data_sources = complete_data.get('data_sources', {})
        internal_data = data_sources.get('internal_data', {})
        
        # Donn√©es internes
        synthesis = internal_data.get('synthesis_file', {})
        csv_files = internal_data.get('csv_files', {})
        
        # R√©cup√©rer les donn√©es de captation depuis Firestore
        captation_content = self.get_captation_results(store_id)
        
        return {
            'store_id': store_id,
            'synthesis': synthesis.get('content', '') if synthesis else '',
            'captation_content': captation_content,
            'csv_files_count': len(csv_files)
        }
    
    def build_clean_prompt(self, store_id: str, client_data: Dict[str, Any], country: str, language: str) -> str:
        """Construit un prompt propre pour l'analyse des cibles clients."""
        
        prompt = f"""Tu es un analyste retail expert. G√©n√®re une analyse des cibles clients DIRECTEMENT UTILISABLE dans un rapport professionnel.

üåç **LOCALISATION ET ACTUALIT√â OBLIGATOIRES:**

- R√âDIGER ENTI√àREMENT la r√©ponse en {language}
- Adapter les r√©f√©rences culturelles et contextuelles au pays {country}

üïê **V√âRIFICATION D'ACTUALIT√â CRITIQUE:**
- PRIORISER uniquement les informations actuelles et v√©rifi√©es (2024-2025)
- EXCLURE les donn√©es manifestement p√©rim√©es ou incertaines
- SIGNALER explicitement toute information douteuse avec "√Ä V√âRIFIER"
- Privil√©gier les tendances et comportements clients R√âCENTS

=== INSTRUCTIONS CRITIQUES ===
- NE PAS inclure de formules de politesse ("Voici", "Absolument", etc.)
- NE PAS mentionner de limitations de donn√©es ou fichiers manquants
- NE PAS r√©p√©ter les instructions
- G√©n√©rer UNIQUEMENT le contenu du rapport
- Format Markdown professionnel
- Ton factuel et analytique
- CONSERVER TOUS LES D√âTAILS des donn√©es ultra enhanced (chiffres exacts, noms pr√©cis, adresses, coordonn√©es)
- D√âVELOPPER EXHAUSTIVEMENT plut√¥t que r√©sumer
- INT√âGRER TOUS les √©l√©ments factuels des analyses sectorielles
- ADAPTER le vocabulaire et les r√©f√©rences au contexte {country}
- **PR√âF√âRER LES TABLEAUX** aux listes complexes pour une meilleure lisibilit√© et mise en forme
- Utiliser des tableaux Markdown pour les donn√©es structur√©es (segments clients, m√©triques, comparaisons)
- √âviter les listes √† puces trop longues ou complexes

=== DONN√âES DISPONIBLES ===

Donn√©es Magasin {store_id}:
{client_data.get('synthesis', 'Donn√©es de synth√®se non disponibles')}

Analyses Sectorielles:
{client_data.get('captation_content', 'Analyses sectorielles non disponibles')}

=== CONTENU √Ä G√âN√âRER ===

## II. √Ä QUI VENDRE (CIBLES CLIENTS)

### 2.1 Segmentation Client√®le Actuelle
[Profils d√©mographiques et socio-√©conomiques des clients existants, comportements d'achat, sports pratiqu√©s, analyses de fid√©lit√©]

### 2.2 Potentiel de Client√®le et Cibles √† Conqu√©rir
[Segments de march√© non exploit√©s, besoins non satisfaits, nouvelles cibles prioritaires, strat√©gies d'acquisition et fid√©lisation]

### 2.3 Parcours Client Omni-canal
[Points de contact, optimisation exp√©rience client, r√¥le du digital, synergies entre canaux]

=== G√âN√âRATION ===
G√©n√®re maintenant le contenu complet et professionnel selon cette structure, en te basant UNIQUEMENT sur les donn√©es fournies.
"""
        
        return prompt
    
    def process_store(self, store_data: Dict[str, Any], country: str, language: str) -> Optional[Dict[str, Any]]:
        """Traite un magasin pour l'analyse des cibles v3."""
        
        store_id = store_data.get('store_id', 'unknown')
        logger.info(f"üë• PROCESSEUR CIBLES v3 - Magasin {store_id}")
        
        try:
            # Initialiser Vertex AI
            if not self.init_vertex_ai():
                return None
            
            # Extraire les donn√©es clients
            client_data = self.extract_client_data(store_data)
            
            # Construire le prompt propre
            prompt = self.build_clean_prompt(store_id, client_data, country, language)
            
            logger.info(f"üë• G√©n√©ration analyse CIBLES v3 magasin {store_id}")
            logger.info(f"üìù Prompt cibles: {len(prompt)} caract√®res")
            
            # G√©n√©rer l'analyse avec retry
            start_time = datetime.now()
            max_retries = 3
            
            for attempt in range(max_retries):
                try:
                    response_text = self.llm_client.generate_simple(
                prompt=prompt,
                max_retries=3,
                temperature=0.2,
                max_tokens=32000
            )
                    break  # Succ√®s, sortir de la boucle
                except Exception as e:
                    if attempt < max_retries - 1:
                        wait_time = (attempt + 1) * 5
                        logger.warning(f"‚ö†Ô∏è Erreur API Vertex (tentative {attempt + 1}/{max_retries}): {e}")
                        logger.info(f"‚è≥ Attente {wait_time}s avant nouvelle tentative...")
                        import time
                        time.sleep(wait_time)
                    else:
                        raise e
            
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            
            if response_text:
                result_length = len(response_text)
                logger.info(f"‚úÖ Cibles v3 g√©n√©r√©es: {result_length} caract√®res en {duration:.1f}s")
                
                return {
                    'section': 'CIBLES',
                    'content': response_text,
                    'metadata': {
                        'store_id': store_id,
                        'generation_time': duration,
                        'input_length': len(prompt),
                        'output_length': result_length,
                        'timestamp': datetime.now().isoformat(),
                        'model_used': MODEL_NAME,
                        'version': 'v3_standardized'
                    }
                }
            else:
                logger.error(f"‚ùå R√©ponse vide pour {store_id}")
                return None
                
        except Exception as e:
            logger.error(f"‚ùå Erreur traitement cibles v3 {store_id}: {e}")
            return None


def main():
    """Point d'entr√©e pour test."""
    processor = PolcoCiblesProcessorV3()
    logger.info("üë• Test Processeur CIBLES v3 (Version Nettoy√©e)")
    logger.info("‚úÖ Processeur CIBLES v3 initialis√©")

if __name__ == "__main__":
    main()
