#!/usr/bin/env python3
"""
POLCO - Processeur de Captation avec Google Search Avanc√©
Utilise les prompts de captation pour obtenir un maximum de contexte local
Int√®gre des requ√™tes Google Search cibl√©es et multiples
"""

import os
import sys
import re
import time
import pandas as pd
from datetime import datetime
from typing import List, Dict, Any, Optional
import json
import logging

# Configuration
PROJECT_ID = "polcoaigeneration-ved6"
REGION = "global"
MODEL_NAME = "gemini-2.5-flash"  # Mod√®le plus puissant pour analyses complexes
CSV_FILE = "polco_mag_test - Feuille 1.csv"
PROMPTS_FILE = "prompts/prompt_captation.md"

# Configuration des logs
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('polco_captation.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class PolcoCaptationProcessor:
    """Processeur POLCO de captation avec Google Search avanc√©."""
    
    def __init__(self):
        """Initialise le processeur de captation."""
        self.project_id = PROJECT_ID
        self.region = "us-central1"  # R√©gion pour Vertex AI
        self.model_name = "gemini-2.5-flash"  # Mod√®le flash pour la captation
        self.prompts = []
        self.stores_df = None
        self.db = None
        self.llm_client = None  # Utilise la classe LLM standardis√©e
        self.stats = {
            'total_stores': 0,
            'processed_stores': 0,
            'successful_prompts': 0,
            'failed_prompts': 0,
            'start_time': None,
            'errors': []
        }
        
        logger.info("üöÄ Initialisation du processeur POLCO Captation avec Google Search Avanc√©")
    
    def check_credentials(self) -> bool:
        """V√©rifie les credentials."""
        if not os.path.exists("credentials.json"):
            logger.error("‚ùå Fichier credentials.json non trouv√©")
            return False
        
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = os.path.abspath("credentials.json")
        logger.info("‚úÖ Credentials configur√©s")
        return True
    
    def init_services(self) -> bool:
        """Initialise les services Google AI et Firestore."""
        try:
            # Initialiser Firestore d'abord
            from google.cloud import firestore
            self.db = firestore.Client(project=self.project_id)
            logger.info("‚úÖ Firestore initialis√©")
            
            # Initialiser le client LLM standardis√© avec gemini-2.5-flash
            from polco_llm_client import get_llm_client
            self.llm_client = get_llm_client("gemini-2.5-flash")
            
            logger.info(f"‚úÖ Client LLM standardis√© initialis√© avec {self.model_name} + Google Search")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur initialisation services: {e}")
            return False
    
    def load_prompts(self) -> bool:
        """Charge les 6 prompts de captation depuis le fichier."""
        try:
            if not os.path.exists(PROMPTS_FILE):
                logger.error(f"‚ùå Fichier {PROMPTS_FILE} non trouv√©")
                return False
            
            with open(PROMPTS_FILE, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Extraire les 7 prompts avec regex am√©lior√©e
            prompt_pattern = r'\*\*Prompt (\d+)\s*:\s*([^*]+)\*\*(.*?)(?=\*\*Prompt \d+|---|\Z)'
            matches = re.findall(prompt_pattern, content, re.DOTALL)
            
            for match in matches:
                prompt_num, title, content = match
                self.prompts.append({
                    'number': int(prompt_num),
                    'title': title.strip(),
                    'content': content.strip()
                })
            
            if len(self.prompts) != 7:
                logger.error(f"‚ùå {len(self.prompts)} prompts trouv√©s, 7 attendus")
                return False
            
            logger.info(f"‚úÖ {len(self.prompts)} prompts de captation charg√©s")
            for prompt in self.prompts:
                logger.info(f"   üìã Prompt {prompt['number']}: {prompt['title']}")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur chargement prompts: {e}")
            return False
    
    def load_stores(self) -> bool:
        """Charge la liste des magasins depuis le CSV."""
        try:
            if not os.path.exists(CSV_FILE):
                logger.error(f"‚ùå Fichier {CSV_FILE} non trouv√©")
                return False
            
            self.stores_df = pd.read_csv(CSV_FILE)
            self.stats['total_stores'] = len(self.stores_df)
            
            logger.info(f"‚úÖ {self.stats['total_stores']} magasins charg√©s depuis {CSV_FILE}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur chargement magasins: {e}")
            return False
    
    def detect_country_and_language(self, store_row, max_retries: int = 3) -> tuple:
        """D√©tecte le pays et la langue via LLM avec une logique de tentatives multiples."""
        try:
            # 1. Pr√©paration du prompt avec les informations du CSV
            store_name = store_row.get('store_name', 'INCONNU')
            ville = store_row.get('ville', '')
            country_name = store_row.get('country_name', 'FRANCE')
            
            # Utiliser la ville du CSV si disponible, sinon extraire du nom
            if ville:
                city_name = ville
            else:
                city_match = re.search(r'(?:DECATHLON\s+)?(.+?)(?:\s+\d+)?$', store_name.strip(), re.IGNORECASE)
                city_name = city_match.group(1).strip() if city_match else store_name.strip()
            
            # Si le pays est d√©j√† dans le CSV, l'utiliser directement
            if country_name and country_name != 'FRANCE':
                # Mapper les pays aux langues
                country_language_map = {
                    'FRANCE': 'Fran√ßais',
                    'ALLEMAGNE': 'Deutsch',
                    'ROYAUME-UNI': 'English',
                    'ESPAGNE': 'Espa√±ol',
                    'ITALIE': 'Italiano',
                    'BELGIQUE': 'Fran√ßais',
                    'SUISSE': 'Deutsch',
                    'PAYS-BAS': 'Nederlands'
                }
                language = country_language_map.get(country_name, 'Fran√ßais')
                logger.info(f"üåç Utilisation pays CSV: {country_name}, {language}")
                return country_name, language
            
            detection_prompt = f"""Dans quel pays est situ√©e la ville "{city_name}", et quelle langue officielle principale y est utilis√©e?

R√©ponds UNIQUEMENT sous ce format exact:
PAYS: [Nom du pays en fran√ßais]
LANGUE: [Langue principale]

Exemples:
- Pour "Forbach": PAYS: France, LANGUE: Fran√ßais  
- Pour "M√ºnchen": PAYS: Allemagne, LANGUE: Deutsch
- Pour "Barcelona": PAYS: Espagne, LANGUE: Espa√±ol
- Pour "Milano": PAYS: Italie, LANGUE: Italiano"""

            # 2. Boucle de tentatives avec le client LLM standardis√©
            for attempt in range(max_retries):
                try:
                    # Utiliser le client LLM standardis√© avec Google Search
                    result = self.llm_client.generate_with_search(
                        prompt=detection_prompt,
                        max_retries=3,
                        temperature=0.1,
                        max_tokens=150
                    )

                    # 3. Validation de la r√©ponse (logique adapt√©e √† cette fonction)
                    if result:
                        country_match = re.search(r'PAYS:\s*([^,\n]+)', result, re.IGNORECASE)
                        language_match = re.search(r'LANGUE:\s*([^,\n]+)', result, re.IGNORECASE)
                        
                        if country_match and language_match:
                            country = country_match.group(1).strip()
                            language = language_match.group(1).strip()
                            logger.info(f"üåç D√©tection LLM r√©ussie: {city_name} -> {country}, {language}")
                            return country, language # Succ√®s, on quitte la fonction
                    
                    logger.warning(f"‚ö†Ô∏è R√©ponse invalide ou mal format√©e pour {store_name} (tentative {attempt + 1}/{max_retries})")

                except Exception as e:
                    logger.error(f"‚ùå Erreur d√©tection LLM pour {store_name} (tentative {attempt + 1}): {e}")
                    if attempt < max_retries - 1:
                        wait_time = (attempt + 1) * 5 # Attente plus courte pour cette fonction rapide
                        logger.info(f"‚è≥ Attente {wait_time}s avant nouvelle tentative...")
                        time.sleep(wait_time)
            
            logger.error(f"‚ùå √âchec d√©finitif de la d√©tection pour {store_name} apr√®s {max_retries} tentatives.")

        except Exception as e:
            # G√®re les erreurs en amont de la boucle (ex: pr√©paration du prompt)
            logger.error(f"‚ùå Erreur critique dans detect_country_and_language pour {store_name}: {e}")

        # 4. Fallback par d√©faut si toutes les tentatives √©chouent
        logger.info(f"üåç Fallback par d√©faut pour {store_name}: France, Fran√ßais")
        return 'France', 'Fran√ßais'

    def create_search_context(self, store_row) -> str:
        """Cr√©e un contexte de recherche cibl√© pour Google Search avec localisation linguistique."""
        store_name = store_row.get('store_name', 'INCONNU')
        
        # D√©tecter le pays et la langue
        country, language = self.detect_country_and_language(store_row)
        
        context = f"""
üåç **LOCALISATION LINGUISTIQUE OBLIGATOIRE :**
- R√âDIGER ENTI√àREMENT la r√©ponse en {language}
- Adapter les r√©f√©rences culturelles et contextuelles au pays {country}
- Utiliser les organismes statistiques locaux du pays

üïê Fiabilit√© & Actualit√© (Protocole de V√©rification Stricte) :
P√©riode de validit√© : Toutes les informations doivent √™tre valides pour 2024-2025.
Processus de validation OBLIGATOIRE pour chaque concurrent :
V√âRIFICATION N¬∞1 (Source prioritaire) : Consulter le localisateur de magasins officiel de l'enseigne (ex: intersport.fr, sport2000.fr). Si le magasin n'y est pas list√©, il est consid√©r√© comme FERM√â.
V√âRIFICATION N¬∞2 (Google Maps) : V√©rifier le statut sur la fiche Google Maps. Rechercher la mention "D√©finitivement ferm√©". Analyser les dates des avis les plus r√©cents. Une absence d'avis r√©cents (< 6 mois) est un signal de fermeture probable.
V√âRIFICATION N¬∞3 (Presse Locale) : En cas de doute, rechercher des articles de presse locale mentionnant une fermeture.
Mention d'incertitude : Si le statut ne peut √™tre confirm√© avec certitude via ces 3 √©tapes, marquer le concurrent comme ‚ö†Ô∏è √Ä V√âRIFIER - STATUT INCERTAIN. Ne jamais affirmer qu'un magasin est ouvert sans preuve formelle issue de l'√©tape 1 ou 2.
Exclusion : Ne mentionner AUCUN magasin si sa fermeture est confirm√©e."
"""
        return context
    
    def create_multi_search_queries(self, store_row, prompt_number: int) -> List[str]:
        """G√©n√®re des requ√™tes Google Search sp√©cialis√©es selon le prompt."""
        # Extraire les informations compl√®tes du magasin
        store_name = store_row.get('store_name', 'INCONNU')
        ville = store_row.get('ville', '')
        codeCP = store_row.get('codeCP', '')
        adress = store_row.get('adress', '')
        country_name = store_row.get('country_name', 'FRANCE')
        
        # Cr√©er l'identifiant complet du magasin
        store_identifier = f" {store_name} {adress} {codeCP} {ville} {country_name}"
        
        # Utiliser la ville comme r√©f√©rence principale pour les recherches
        city = ville if ville else store_name
        
        # Requ√™tes sp√©cialis√©es par prompt
        queries_by_prompt = {
            1: [  # Zone de chalandise
                f"Decathlon {city} adresse exacte coordonn√©es GPS",
                f"magasins Decathlon pr√®s {city} distances kilom√®tres",
                f"{city} zone commerciale Actisud centre ville",
                f"transport public {city} bus m√©tro desserte",
                f"axes routiers {city} autoroute nationale d√©partementale"
            ],
            2: [  # SWOT
                f"Decathlon {city} avis clients Google Pages Jaunes",
                f"magasins sport {city} concurrents Intersport Go Sport",
                f"{city} parking Decathlon accessibilit√© transports",
                f"projets urbanisme {city} zones commerciales",
                f"{city} √©conomie locale emploi entreprises"
            ],
            3: [  # D√©mographie
                f"{city} population INSEE d√©mographie √¢ge revenus",
                f"{city} familles enfants composition m√©nages",
                f"{city} CSP cadres employ√©s ouvriers statistiques",
                f"{city} revenu m√©dian pouvoir achat niveau vie",
                f"{city} g√©ographie relief altitude lacs rivi√®res"
            ],
            4: [  # Tourisme/Infrastructures
                f"{city} tourisme nombre visiteurs h√©bergements",
                f"stades {city} terrains sport football capacit√©",
                f"piscines {city} centre aquatique horaires tarifs",
                f"pistes cyclables {city} v√©lo itin√©raires kilom√®tres",
                f"salles sport fitness {city} musculation tarifs"
            ],
            5: [  # Concurrence
                f"magasins sport {city} adresses Sport 2000 Intersport",
                f"sp√©cialistes sport {city} running v√©lo tennis",
                f"clubs sportifs {city} licenci√©s adh√©rents football",
                f"√©v√©nements sportifs {city} courses marathon trail",
                f"salles fitness {city} Basic-Fit prix abonnements"
            ],
            6: [  # Mobilit√©/Potentiel
                f"{city} mobilit√© v√©lo marche transport modes",
                f"infrastructures cyclables {city} pistes bandes",
                f"pratiques sportives {city} sports populaires",
                f"licenci√©s sport {city} f√©d√©rations donn√©es",
                f"march√© sport {city} √©quipements budget d√©penses"
            ],
            7: [  # Concurrence d√©taill√©e
                f"magasins Decathlon {city} zone chalandise 50km",
                f"Intersport Sport2000 {city} adresses magasins",
                f"concurrents sport {city} grandes surfaces Leclerc Carrefour",
                f"sp√©cialistes sport {city} ind√©pendants franchises",
                f"magasins fermeture {city} presse locale articles"
            ]
        }
        
        return queries_by_prompt.get(prompt_number, [f"{city} sport infrastructure"])
    
    def execute_captation_prompt(self, store_row, prompt_content: str, prompt_number: int, context: str, max_retries: int = 3) -> Optional[str]:
        """Ex√©cute un prompt avec recherches Google multiples et cibl√©es."""
        
        # Extraire les informations compl√®tes du magasin
        store_name = store_row.get('store_name', 'INCONNU')
        ville = store_row.get('ville', '')
        codeCP = store_row.get('codeCP', '')
        adress = store_row.get('adress', '')
        country_name = store_row.get('country_name', 'FRANCE')
        
        # Cr√©er l'identifiant complet du magasin pour remplacer XXXX
        store_identifier = f" {store_name} {adress} {codeCP} {ville} {country_name}"
        
        # G√©n√©rer des requ√™tes de recherche sp√©cialis√©es
        search_queries = self.create_multi_search_queries(store_row, prompt_number)       
       
        full_prompt = f"""

{prompt_content.replace('XXXX', store_identifier)}

RAPPEL CRITIQUE: Utilise Google Search pour obtenir des informations pr√©cises, r√©centes et v√©rifiables. Ne te contente pas de g√©n√©ralit√©s.
"""
        #logger.info(f"üîç Prompt envoy√© : {full_prompt}...")
        for attempt in range(max_retries):
            try:
                logger.info(f"üîç Recherche Google avanc√©e pour prompt {prompt_number}...")
                logger.info(f"üìã {len(search_queries)} requ√™tes cibl√©es pr√©par√©es")
                
                # Utiliser le client LLM standardis√© avec Google Search
                response_text = self.llm_client.generate_with_search(
                    prompt=full_prompt,
                    max_retries=3,
                    temperature=0.1,
                    max_tokens=8192
                )
                
                if response_text and len(response_text) > 100:
                    logger.info(f"‚úÖ Prompt {prompt_number} r√©ussi ({len(response_text)} chars)")
                    return response_text
                else:
                    logger.warning(f"‚ö†Ô∏è R√©ponse courte pour prompt {prompt_number} (tentative {attempt + 1})")
                    
            except Exception as e:
                logger.error(f"‚ùå Erreur prompt {prompt_number} (tentative {attempt + 1}): {e}")
                if attempt < max_retries - 1:
                    wait_time = (attempt + 1) * 10
                    logger.info(f"‚è≥ Attente {wait_time}s avant nouvelle tentative...")
                    time.sleep(wait_time)
        
        logger.error(f"‚ùå √âchec d√©finitif prompt {prompt_number} apr√®s {max_retries} tentatives")
        return None
    
    def process_store(self, store_row) -> Dict[str, Any]:
        """Traite un magasin avec les 7 prompts de captation."""
        store_id = store_row.get('store_id', 'N/A')
        store_name = store_row.get('store_name', 'INCONNU')
        
        logger.info(f"üè™ Traitement magasin {store_name} (ID: {store_id})")
        
        # Cr√©er le contexte de recherche enrichi
        context = self.create_search_context(store_row)
        
        # Structure pour sauvegarder les r√©sultats
        store_result = {
            'store_id': store_id,
            'store_name': store_name,
            'processing_date': datetime.now().isoformat(),
            'status': 'processing',
            'prompts_results': {},
            'metadata': {
                'model_used': self.model_name,
                'google_search': True,
                'total_prompts': len(self.prompts)
            },
            'summary': {}
        }
        
        successful_prompts = 0
        
        # Traiter chaque prompt
        for prompt in self.prompts:
            prompt_key = f"prompt_{prompt['number']}"
            logger.info(f"üìù Prompt {prompt['number']}: {prompt['title']}")
            
            start_time = time.time()
            
            # Ex√©cuter le prompt avec recherche Google ultra-cibl√©e
            result = self.execute_captation_prompt(
                store_row, 
                prompt['content'], 
                prompt['number'],
                context
            )
            
            execution_time = time.time() - start_time
            
            if result:
                store_result['prompts_results'][prompt_key] = {
                    'question': prompt['content'],
                    'response': result,
                    'status': 'completed',
                    'timestamp': datetime.now().isoformat(),
                    'execution_time': execution_time,
                    'title': prompt['title'],
                    'model': self.model_name,
                    'features': ['google_search', 'multi_queries']
                }
                successful_prompts += 1
                self.stats['successful_prompts'] += 1
                logger.info(f"‚úÖ Prompt {prompt['number']} termin√© ({execution_time:.1f}s)")
            else:
                store_result['prompts_results'][prompt_key] = {
                    'question': prompt['content'],
                    'response': None,
                    'status': 'failed',
                    'timestamp': datetime.now().isoformat(),
                    'execution_time': execution_time,
                    'title': prompt['title'],
                    'error': '√âchec apr√®s plusieurs tentatives'
                }
                self.stats['failed_prompts'] += 1
                logger.error(f"‚ùå Prompt {prompt['number']} √©chou√©")
            
            # Pause entre prompts pour √©viter rate limiting
            time.sleep(5)
        
        # Finaliser le r√©sultat
        store_result['status'] = 'completed' if successful_prompts > 0 else 'failed'
        store_result['summary'] = {
            'total_prompts': len(self.prompts),
            'successful_prompts': successful_prompts,
            'failed_prompts': len(self.prompts) - successful_prompts,
            'completion_rate': successful_prompts / len(self.prompts) * 100
        }
        
        logger.info(f"üéØ Magasin {store_name}: {successful_prompts}/{len(self.prompts)} prompts r√©ussis")
        
        return store_result
    
    def save_to_firestore(self, store_result: Dict[str, Any]) -> bool:
        """Sauvegarde les r√©sultats dans Firestore."""
        try:
            doc_name = f"store_{store_result['store_id']}"
            doc_ref = self.db.collection('polco_magasins_captation').document(doc_name)
            doc_ref.set(store_result)
            
            logger.info(f"üíæ Sauvegard√©: {doc_name}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur sauvegarde Firestore: {e}")
            return False
    
    def run(self, limit: Optional[int] = None, test_mode: bool = False, store_id: Optional[str] = None):
        """Lance le traitement POLCO Captation."""
        logger.info("üöÄ D√©marrage du traitement POLCO Captation")
        logger.info("=" * 80)
        
        self.stats['start_time'] = datetime.now()
        
        # V√©rifications
        if not self.check_credentials():
            return False
        
        if not self.init_services():
            return False
        
        if not self.load_prompts():
            return False
        
        if not self.load_stores():
            return False
        
        # Mode test, limite ou magasin sp√©cifique
        stores_to_process = self.stores_df
        
        if store_id:
            # Filtrer uniquement le magasin sp√©cifi√©
            stores_to_process = self.stores_df[self.stores_df['store_id'].astype(str) == str(store_id)]
            if stores_to_process.empty:
                logger.error(f"‚ùå Magasin ID '{store_id}' non trouv√© dans le CSV")
                logger.info("üìã Magasins disponibles:")
                for _, row in self.stores_df.iterrows():
                    logger.info(f"   ‚Ä¢ {row['store_id']} - {row['store_name']}")
                return False
            logger.info(f"üéØ Mode magasin sp√©cifique: {stores_to_process.iloc[0]['store_name']} (ID: {store_id})")
        elif test_mode or limit:
            n = limit if limit else 1
            stores_to_process = self.stores_df.head(n)
            logger.info(f"üß™ Mode test activ√©: traitement de {len(stores_to_process)} magasin(s)")
        
        logger.info(f"üìä {len(stores_to_process)} magasins √† traiter")
        logger.info(f"üìã 7 prompts de captation par magasin")
        logger.info(f"üîç Recherche Google multi-requ√™tes activ√©e")
        logger.info(f"‚è±Ô∏è Temps estim√©: {len(stores_to_process) * 8:.0f} minutes")
        logger.info("")
        
        # Traiter chaque magasin
        for index, store_row in stores_to_process.iterrows():
            try:
                logger.info(f"üè™ [{index + 1}/{len(stores_to_process)}] {store_row.get('store_name', 'INCONNU')}")
                
                # Traiter le magasin
                store_result = self.process_store(store_row)
                
                # Sauvegarder
                if self.save_to_firestore(store_result):
                    self.stats['processed_stores'] += 1
                
            except KeyboardInterrupt:
                logger.info("\n‚èπÔ∏è Traitement interrompu par l'utilisateur")
                break
            except Exception as e:
                logger.error(f"‚ùå Erreur traitement magasin {store_row.get('store_name', 'INCONNU')}: {e}")
                self.stats['errors'].append(str(e))
        
        # Rapport final
        end_time = datetime.now()
        duration = (end_time - self.stats['start_time']).total_seconds()
        
        logger.info("")
        logger.info("=" * 80)
        logger.info("üìä POLCO CAPTATION - RAPPORT FINAL")
        logger.info("=" * 80)
        logger.info(f"‚è±Ô∏è Dur√©e totale: {duration/60:.1f} minutes")
        logger.info(f"üè™ Magasins trait√©s: {self.stats['processed_stores']}/{self.stats['total_stores']}")
        logger.info(f"‚úÖ Prompts r√©ussis: {self.stats['successful_prompts']}")
        logger.info(f"‚ùå Prompts √©chou√©s: {self.stats['failed_prompts']}")
        logger.info(f"üìà Taux de r√©ussite: {self.stats['successful_prompts']/(self.stats['successful_prompts']+self.stats['failed_prompts'])*100:.1f}%")
        logger.info(f"üóÑÔ∏è Collection Firestore: polco_magasins_captation")
        logger.info("")
        logger.info("üéâ Traitement POLCO Captation termin√© !")
        
        return True


def main():
    """Point d'entr√©e principal."""
    import argparse
    
    parser = argparse.ArgumentParser(description='POLCO Captation - Google Search Avanc√©')
    parser.add_argument('--test', action='store_true', help='Mode test (1 magasin)')
    parser.add_argument('--limit', type=int, help='Nombre de magasins √† traiter')
    parser.add_argument('--store-id', type=str, help='Traiter uniquement le magasin avec cet ID')
    
    args = parser.parse_args()
    
    processor = PolcoCaptationProcessor()
    
    try:
        processor.run(
            limit=args.limit,
            test_mode=args.test,
            store_id=getattr(args, 'store_id', None)
        )
    except KeyboardInterrupt:
        logger.info("\n‚èπÔ∏è Processus interrompu")
        sys.exit(0)
    except Exception as e:
        logger.error(f"‚ùå Erreur fatale: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
