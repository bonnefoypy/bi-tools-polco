#!/usr/bin/env python3
"""
POLCO - Processeur de Captation avec Google Search AvancÃ©
Utilise les prompts de captation pour obtenir un maximum de contexte local
IntÃ¨gre des requÃªtes Google Search ciblÃ©es et multiples
"""

import os
import sys
import re
import time
import pandas as pd
from datetime import datetime
from typing import List, Dict, Any, Optional
import json
import logging

# Configuration
PROJECT_ID = "polcoaigeneration-ved6"
REGION = "global"
MODEL_NAME = "gemini-2.5-flash"  # ModÃ¨le plus puissant pour analyses complexes
CSV_FILE = "polco_mag_test - Feuille 1.csv"
PROMPTS_FILE = "prompts/prompt_captation.md"

# Configuration des logs
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('polco_captation.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class PolcoCaptationProcessor:
    """Processeur POLCO de captation avec Google Search avancÃ©."""
    
    def __init__(self):
        """Initialise le processeur de captation."""
        self.project_id = PROJECT_ID
        self.region = "us-central1"  # RÃ©gion pour Vertex AI
        self.model_name = "gemini-2.5-flash"  # ModÃ¨le flash pour la captation
        self.prompts = []
        self.stores_df = None
        self.db = None
        self.llm_client = None  # Utilise la classe LLM standardisÃ©e
        self.stats = {
            'total_stores': 0,
            'processed_stores': 0,
            'successful_prompts': 0,
            'failed_prompts': 0,
            'start_time': None,
            'errors': []
        }
        
        logger.info("ğŸš€ Initialisation du processeur POLCO Captation avec Google Search AvancÃ©")
    
    def check_credentials(self) -> bool:
        """VÃ©rifie les credentials."""
        if not os.path.exists("credentials.json"):
            logger.error("âŒ Fichier credentials.json non trouvÃ©")
            return False
        
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = os.path.abspath("credentials.json")
        logger.info("âœ… Credentials configurÃ©s")
        return True
    
    def init_services(self) -> bool:
        """Initialise les services Google AI et Firestore."""
        try:
            # Initialiser Firestore d'abord
            from google.cloud import firestore
            self.db = firestore.Client(project=self.project_id)
            logger.info("âœ… Firestore initialisÃ©")
            
            # Initialiser le client LLM standardisÃ© avec gemini-2.5-flash
            from polco_llm_client import get_llm_client
            self.llm_client = get_llm_client("gemini-2.5-flash")
            
            logger.info(f"âœ… Client LLM standardisÃ© initialisÃ© avec {self.model_name} + Google Search")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ Erreur initialisation services: {e}")
            return False
    
    def load_prompts(self) -> bool:
        """Charge les 6 prompts de captation depuis le fichier."""
        try:
            if not os.path.exists(PROMPTS_FILE):
                logger.error(f"âŒ Fichier {PROMPTS_FILE} non trouvÃ©")
                return False
            
            with open(PROMPTS_FILE, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Extraire les 7 prompts avec regex amÃ©liorÃ©e
            prompt_pattern = r'\*\*Prompt (\d+)\s*:\s*([^*]+)\*\*(.*?)(?=\*\*Prompt \d+|---|\Z)'
            matches = re.findall(prompt_pattern, content, re.DOTALL)
            
            for match in matches:
                prompt_num, title, content = match
                self.prompts.append({
                    'number': int(prompt_num),
                    'title': title.strip(),
                    'content': content.strip()
                })
            
            if len(self.prompts) != 7:
                logger.error(f"âŒ {len(self.prompts)} prompts trouvÃ©s, 7 attendus")
                return False
            
            logger.info(f"âœ… {len(self.prompts)} prompts de captation chargÃ©s")
            for prompt in self.prompts:
                logger.info(f"   ğŸ“‹ Prompt {prompt['number']}: {prompt['title']}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ Erreur chargement prompts: {e}")
            return False
    
    def load_stores(self) -> bool:
        """Charge la liste des magasins depuis le CSV."""
        try:
            if not os.path.exists(CSV_FILE):
                logger.error(f"âŒ Fichier {CSV_FILE} non trouvÃ©")
                return False
            
            self.stores_df = pd.read_csv(CSV_FILE)
            self.stats['total_stores'] = len(self.stores_df)
            
            logger.info(f"âœ… {self.stats['total_stores']} magasins chargÃ©s depuis {CSV_FILE}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Erreur chargement magasins: {e}")
            return False
    
    def detect_country_and_language(self, store_row, max_retries: int = 3) -> tuple:
        """DÃ©tecte le pays et la langue via LLM avec une logique de tentatives multiples."""
        try:
            # 1. PrÃ©paration du prompt avec les informations du CSV
            store_name = store_row.get('store_name', 'INCONNU')
            ville = store_row.get('ville', '')
            country_name = store_row.get('country_name', 'FRANCE')
            
            # Utiliser la ville du CSV si disponible, sinon extraire du nom
            if ville:
                city_name = ville
            else:
                city_match = re.search(r'(?:DECATHLON\s+)?(.+?)(?:\s+\d+)?$', store_name.strip(), re.IGNORECASE)
                city_name = city_match.group(1).strip() if city_match else store_name.strip()
            
            # Si le pays est dÃ©jÃ  dans le CSV, l'utiliser directement
            if country_name and country_name != 'FRANCE':
                # Mapper les pays aux langues
                country_language_map = {
                    'FRANCE': 'FranÃ§ais',
                    'ALLEMAGNE': 'Deutsch',
                    'ROYAUME-UNI': 'English',
                    'ESPAGNE': 'EspaÃ±ol',
                    'ITALIE': 'Italiano',
                    'BELGIQUE': 'FranÃ§ais',
                    'SUISSE': 'Deutsch',
                    'PAYS-BAS': 'Nederlands'
                }
                language = country_language_map.get(country_name, 'FranÃ§ais')
                logger.info(f"ğŸŒ Utilisation pays CSV: {country_name}, {language}")
                return country_name, language
            
            detection_prompt = f"""Dans quel pays est situÃ©e la ville "{city_name}", et quelle langue officielle principale y est utilisÃ©e?

RÃ©ponds UNIQUEMENT sous ce format exact:
PAYS: [Nom du pays en franÃ§ais]
LANGUE: [Langue principale]

Exemples:
- Pour "Forbach": PAYS: France, LANGUE: FranÃ§ais  
- Pour "MÃ¼nchen": PAYS: Allemagne, LANGUE: Deutsch
- Pour "Barcelona": PAYS: Espagne, LANGUE: EspaÃ±ol
- Pour "Milano": PAYS: Italie, LANGUE: Italiano"""

            # 2. Boucle de tentatives avec le client LLM standardisÃ©
            for attempt in range(max_retries):
                try:
                    # Utiliser le client LLM standardisÃ© avec Google Search
                    result = self.llm_client.generate_with_search(
                        prompt=detection_prompt,
                        max_retries=3,
                        temperature=0.1,
                        max_tokens=150
                    )

                    # 3. Validation de la rÃ©ponse (logique adaptÃ©e Ã  cette fonction)
                    if result:
                        country_match = re.search(r'PAYS:\s*([^,\n]+)', result, re.IGNORECASE)
                        language_match = re.search(r'LANGUE:\s*([^,\n]+)', result, re.IGNORECASE)
                        
                        if country_match and language_match:
                            country = country_match.group(1).strip()
                            language = language_match.group(1).strip()
                            logger.info(f"ğŸŒ DÃ©tection LLM rÃ©ussie: {city_name} -> {country}, {language}")
                            return country, language # SuccÃ¨s, on quitte la fonction
                    
                    logger.warning(f"âš ï¸ RÃ©ponse invalide ou mal formatÃ©e pour {store_name} (tentative {attempt + 1}/{max_retries})")

                except Exception as e:
                    logger.error(f"âŒ Erreur dÃ©tection LLM pour {store_name} (tentative {attempt + 1}): {e}")
                    if attempt < max_retries - 1:
                        wait_time = (attempt + 1) * 5 # Attente plus courte pour cette fonction rapide
                        logger.info(f"â³ Attente {wait_time}s avant nouvelle tentative...")
                        time.sleep(wait_time)
            
            logger.error(f"âŒ Ã‰chec dÃ©finitif de la dÃ©tection pour {store_name} aprÃ¨s {max_retries} tentatives.")

        except Exception as e:
            # GÃ¨re les erreurs en amont de la boucle (ex: prÃ©paration du prompt)
            logger.error(f"âŒ Erreur critique dans detect_country_and_language pour {store_name}: {e}")

        # 4. Fallback par dÃ©faut si toutes les tentatives Ã©chouent
        logger.info(f"ğŸŒ Fallback par dÃ©faut pour {store_name}: France, FranÃ§ais")
        return 'France', 'FranÃ§ais'

    def create_search_context(self, store_row) -> str:
        """CrÃ©e un contexte de recherche ciblÃ© pour Google Search avec localisation linguistique."""
        store_name = store_row.get('store_name', 'INCONNU')
        
        # DÃ©tecter le pays et la langue
        country, language = self.detect_country_and_language(store_row)
        
        context = f"""
ğŸŒ **LOCALISATION LINGUISTIQUE OBLIGATOIRE :**
- RÃ‰DIGER ENTIÃˆREMENT la rÃ©ponse en {language}
- Adapter les rÃ©fÃ©rences culturelles et contextuelles au pays {country}
- Utiliser les organismes statistiques locaux du pays

ğŸ• FiabilitÃ© & ActualitÃ© (Protocole de VÃ©rification Stricte) :
PÃ©riode de validitÃ© : Toutes les informations doivent Ãªtre valides pour 2024-2025.
Processus de validation OBLIGATOIRE pour chaque concurrent :
VÃ‰RIFICATION NÂ°1 (Source prioritaire) : Consulter le localisateur de magasins officiel de l'enseigne (ex: intersport.fr, sport2000.fr). Si le magasin n'y est pas listÃ©, il est considÃ©rÃ© comme FERMÃ‰.
VÃ‰RIFICATION NÂ°2 (Google Maps) : VÃ©rifier le statut sur la fiche Google Maps. Rechercher la mention "DÃ©finitivement fermÃ©". Analyser les dates des avis les plus rÃ©cents. Une absence d'avis rÃ©cents (< 6 mois) est un signal de fermeture probable.
VÃ‰RIFICATION NÂ°3 (Presse Locale) : En cas de doute, rechercher des articles de presse locale mentionnant une fermeture.
Mention d'incertitude : Si le statut ne peut Ãªtre confirmÃ© avec certitude via ces 3 Ã©tapes, marquer le concurrent comme âš ï¸ Ã€ VÃ‰RIFIER - STATUT INCERTAIN. Ne jamais affirmer qu'un magasin est ouvert sans preuve formelle issue de l'Ã©tape 1 ou 2.
Exclusion : Ne mentionner AUCUN magasin si sa fermeture est confirmÃ©e."
"""
        return context
    
    def create_multi_search_queries(self, store_row, prompt_number: int) -> List[str]:
        """GÃ©nÃ¨re des requÃªtes Google Search spÃ©cialisÃ©es selon le prompt."""
        # Extraire les informations complÃ¨tes du magasin
        store_name = store_row.get('store_name', 'INCONNU')
        ville = store_row.get('ville', '')
        codeCP = store_row.get('codeCP', '')
        adress = store_row.get('adress', '')
        country_name = store_row.get('country_name', 'FRANCE')
        
        # CrÃ©er l'identifiant complet du magasin
        store_identifier = f" {store_name} {adress} {codeCP} {ville} {country_name}"
        
        # Utiliser la ville comme rÃ©fÃ©rence principale pour les recherches
        city = ville if ville else store_name
        
        # RequÃªtes spÃ©cialisÃ©es par prompt
        queries_by_prompt = {
            1: [  # Zone de chalandise
                f"Decathlon {city} adresse exacte coordonnÃ©es GPS",
                f"magasins Decathlon prÃ¨s {city} distances kilomÃ¨tres",
                f"{city} zone commerciale Actisud centre ville",
                f"transport public {city} bus mÃ©tro desserte",
                f"axes routiers {city} autoroute nationale dÃ©partementale"
            ],
            2: [  # SWOT
                f"Decathlon {city} avis clients Google Pages Jaunes",
                f"magasins sport {city} concurrents Intersport Go Sport",
                f"{city} parking Decathlon accessibilitÃ© transports",
                f"projets urbanisme {city} zones commerciales",
                f"{city} Ã©conomie locale emploi entreprises"
            ],
            3: [  # DÃ©mographie
                f"{city} population INSEE dÃ©mographie Ã¢ge revenus",
                f"{city} familles enfants composition mÃ©nages",
                f"{city} CSP cadres employÃ©s ouvriers statistiques",
                f"{city} revenu mÃ©dian pouvoir achat niveau vie",
                f"{city} gÃ©ographie relief altitude lacs riviÃ¨res"
            ],
            4: [  # Tourisme/Infrastructures
                f"{city} tourisme nombre visiteurs hÃ©bergements",
                f"stades {city} terrains sport football capacitÃ©",
                f"piscines {city} centre aquatique horaires tarifs",
                f"pistes cyclables {city} vÃ©lo itinÃ©raires kilomÃ¨tres",
                f"salles sport fitness {city} musculation tarifs"
            ],
            5: [  # Concurrence
                f"magasins sport {city} adresses Sport 2000 Intersport",
                f"spÃ©cialistes sport {city} running vÃ©lo tennis",
                f"clubs sportifs {city} licenciÃ©s adhÃ©rents football",
                f"Ã©vÃ©nements sportifs {city} courses marathon trail",
                f"salles fitness {city} Basic-Fit prix abonnements"
            ],
            6: [  # MobilitÃ©/Potentiel
                f"{city} mobilitÃ© vÃ©lo marche transport modes",
                f"infrastructures cyclables {city} pistes bandes",
                f"pratiques sportives {city} sports populaires",
                f"licenciÃ©s sport {city} fÃ©dÃ©rations donnÃ©es",
                f"marchÃ© sport {city} Ã©quipements budget dÃ©penses"
            ],
            7: [  # Concurrence dÃ©taillÃ©e
                f"magasins Decathlon {city} zone chalandise 50km",
                f"Intersport Sport2000 {city} adresses magasins",
                f"concurrents sport {city} grandes surfaces Leclerc Carrefour",
                f"spÃ©cialistes sport {city} indÃ©pendants franchises",
                f"magasins fermeture {city} presse locale articles"
            ]
        }
        
        return queries_by_prompt.get(prompt_number, [f"{city} sport infrastructure"])
    
    def execute_captation_prompt(self, store_row, prompt_content: str, prompt_number: int, context: str, max_retries: int = 3) -> Optional[str]:
        """ExÃ©cute un prompt avec recherches Google multiples et ciblÃ©es."""
        
        # Extraire les informations complÃ¨tes du magasin
        store_name = store_row.get('store_name', 'INCONNU')
        ville = store_row.get('ville', '')
        codeCP = store_row.get('codeCP', '')
        adress = store_row.get('adress', '')
        country_name = store_row.get('country_name', 'FRANCE')
        
        # CrÃ©er l'identifiant complet du magasin pour remplacer XXXX
        store_identifier = f" {store_name} {adress} {codeCP} {ville} {country_name}"
        
        # GÃ©nÃ©rer des requÃªtes de recherche spÃ©cialisÃ©es
        search_queries = self.create_multi_search_queries(store_row, prompt_number)       
       
        full_prompt = f"""

{prompt_content.replace('XXXX', store_identifier)}

RAPPEL CRITIQUE: Utilise Google Search pour obtenir des informations prÃ©cises, rÃ©centes et vÃ©rifiables. Ne te contente pas de gÃ©nÃ©ralitÃ©s.
"""
        #logger.info(f"ğŸ” Prompt envoyÃ© : {full_prompt}...")
        for attempt in range(max_retries):
            try:
                logger.info(f"ğŸ” Recherche Google avancÃ©e pour prompt {prompt_number}...")
                logger.info(f"ğŸ“‹ {len(search_queries)} requÃªtes ciblÃ©es prÃ©parÃ©es")
                
                # Utiliser le client LLM standardisÃ© avec Google Search
                response_text = self.llm_client.generate_with_search(
                    prompt=full_prompt,
                    max_retries=3,
                    temperature=0.1,
                    max_tokens=8192
                )
                
                if response_text and len(response_text) > 100:
                    logger.info(f"âœ… Prompt {prompt_number} rÃ©ussi ({len(response_text)} chars)")
                    return response_text
                else:
                    logger.warning(f"âš ï¸ RÃ©ponse courte pour prompt {prompt_number} (tentative {attempt + 1})")
                    
            except Exception as e:
                logger.error(f"âŒ Erreur prompt {prompt_number} (tentative {attempt + 1}): {e}")
                if attempt < max_retries - 1:
                    wait_time = (attempt + 1) * 10
                    logger.info(f"â³ Attente {wait_time}s avant nouvelle tentative...")
                    time.sleep(wait_time)
        
        logger.error(f"âŒ Ã‰chec dÃ©finitif prompt {prompt_number} aprÃ¨s {max_retries} tentatives")
        return None
    
    def process_store(self, store_row) -> Dict[str, Any]:
        """Traite un magasin avec les 7 prompts de captation."""
        store_id = store_row.get('store_id', 'N/A')
        store_name = store_row.get('store_name', 'INCONNU')
        
        logger.info(f"ğŸª Traitement magasin {store_name} (ID: {store_id})")
        
        # CrÃ©er le contexte de recherche enrichi
        context = self.create_search_context(store_row)
        
        # Structure pour sauvegarder les rÃ©sultats
        store_result = {
            'store_id': store_id,
            'store_name': store_name,
            'processing_date': datetime.now().isoformat(),
            'status': 'processing',
            'prompts_results': {},
            'metadata': {
                'model_used': self.model_name,
                'google_search': True,
                'total_prompts': len(self.prompts)
            },
            'summary': {}
        }
        
        successful_prompts = 0
        
        # Traiter chaque prompt
        for prompt in self.prompts:
            prompt_key = f"prompt_{prompt['number']}"
            logger.info(f"ğŸ“ Prompt {prompt['number']}: {prompt['title']}")
            
            start_time = time.time()
            
            # ExÃ©cuter le prompt avec recherche Google ultra-ciblÃ©e
            result = self.execute_captation_prompt(
                store_row, 
                prompt['content'], 
                prompt['number'],
                context
            )
            
            execution_time = time.time() - start_time
            
            if result:
                store_result['prompts_results'][prompt_key] = {
                    'question': prompt['content'],
                    'response': result,
                    'status': 'completed',
                    'timestamp': datetime.now().isoformat(),
                    'execution_time': execution_time,
                    'title': prompt['title'],
                    'model': self.model_name,
                    'features': ['google_search', 'multi_queries']
                }
                successful_prompts += 1
                self.stats['successful_prompts'] += 1
                logger.info(f"âœ… Prompt {prompt['number']} terminÃ© ({execution_time:.1f}s)")
            else:
                store_result['prompts_results'][prompt_key] = {
                    'question': prompt['content'],
                    'response': None,
                    'status': 'failed',
                    'timestamp': datetime.now().isoformat(),
                    'execution_time': execution_time,
                    'title': prompt['title'],
                    'error': 'Ã‰chec aprÃ¨s plusieurs tentatives'
                }
                self.stats['failed_prompts'] += 1
                logger.error(f"âŒ Prompt {prompt['number']} Ã©chouÃ©")
            
            # Pause entre prompts pour Ã©viter rate limiting
            time.sleep(5)
        
        # Finaliser le rÃ©sultat
        store_result['status'] = 'completed' if successful_prompts > 0 else 'failed'
        store_result['summary'] = {
            'total_prompts': len(self.prompts),
            'successful_prompts': successful_prompts,
            'failed_prompts': len(self.prompts) - successful_prompts,
            'completion_rate': successful_prompts / len(self.prompts) * 100
        }
        
        logger.info(f"ğŸ¯ Magasin {store_name}: {successful_prompts}/{len(self.prompts)} prompts rÃ©ussis")
        
        return store_result
    
    def save_to_firestore(self, store_result: Dict[str, Any]) -> bool:
        """Sauvegarde les rÃ©sultats dans Firestore."""
        try:
            doc_name = f"store_{store_result['store_id']}"
            doc_ref = self.db.collection('polco_magasins_captation').document(doc_name)
            doc_ref.set(store_result)
            
            logger.info(f"ğŸ’¾ SauvegardÃ©: {doc_name}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Erreur sauvegarde Firestore: {e}")
            return False
    
    def run(self, limit: Optional[int] = None, test_mode: bool = False, store_id: Optional[str] = None):
        """Lance le traitement POLCO Captation."""
        logger.info("ğŸš€ DÃ©marrage du traitement POLCO Captation")
        logger.info("=" * 80)
        
        self.stats['start_time'] = datetime.now()
        
        # VÃ©rifications
        if not self.check_credentials():
            return False
        
        if not self.init_services():
            return False
        
        if not self.load_prompts():
            return False
        
        if not self.load_stores():
            return False
        
        # Mode test, limite ou magasin spÃ©cifique
        stores_to_process = self.stores_df
        
        if store_id:
            # Filtrer uniquement le magasin spÃ©cifiÃ©
            stores_to_process = self.stores_df[self.stores_df['store_id'].astype(str) == str(store_id)]
            if stores_to_process.empty:
                logger.error(f"âŒ Magasin ID '{store_id}' non trouvÃ© dans le CSV")
                logger.info("ğŸ“‹ Magasins disponibles:")
                for _, row in self.stores_df.iterrows():
                    logger.info(f"   â€¢ {row['store_id']} - {row['store_name']}")
                return False
            logger.info(f"ğŸ¯ Mode magasin spÃ©cifique: {stores_to_process.iloc[0]['store_name']} (ID: {store_id})")
        elif test_mode or limit:
            n = limit if limit else 1
            stores_to_process = self.stores_df.head(n)
            logger.info(f"ğŸ§ª Mode test activÃ©: traitement de {len(stores_to_process)} magasin(s)")
        
        logger.info(f"ğŸ“Š {len(stores_to_process)} magasins Ã  traiter")
        logger.info(f"ğŸ“‹ 7 prompts de captation par magasin")
        logger.info(f"ğŸ” Recherche Google multi-requÃªtes activÃ©e")
        logger.info(f"â±ï¸ Temps estimÃ©: {len(stores_to_process) * 8:.0f} minutes")
        logger.info("")
        
        # Traiter chaque magasin
        for index, store_row in stores_to_process.iterrows():
            try:
                logger.info(f"ğŸª [{index + 1}/{len(stores_to_process)}] {store_row.get('store_name', 'INCONNU')}")
                
                # Traiter le magasin
                store_result = self.process_store(store_row)
                
                # Sauvegarder
                if self.save_to_firestore(store_result):
                    self.stats['processed_stores'] += 1
                
            except KeyboardInterrupt:
                logger.info("\nâ¹ï¸ Traitement interrompu par l'utilisateur")
                break
            except Exception as e:
                logger.error(f"âŒ Erreur traitement magasin {store_row.get('store_name', 'INCONNU')}: {e}")
                self.stats['errors'].append(str(e))
        
        # Rapport final
        end_time = datetime.now()
        duration = (end_time - self.stats['start_time']).total_seconds()
        
        logger.info("")
        logger.info("=" * 80)
        logger.info("ğŸ“Š POLCO CAPTATION - RAPPORT FINAL")
        logger.info("=" * 80)
        logger.info(f"â±ï¸ DurÃ©e totale: {duration/60:.1f} minutes")
        logger.info(f"ğŸª Magasins traitÃ©s: {self.stats['processed_stores']}/{self.stats['total_stores']}")
        logger.info(f"âœ… Prompts rÃ©ussis: {self.stats['successful_prompts']}")
        logger.info(f"âŒ Prompts Ã©chouÃ©s: {self.stats['failed_prompts']}")
        logger.info(f"ğŸ“ˆ Taux de rÃ©ussite: {self.stats['successful_prompts']/(self.stats['successful_prompts']+self.stats['failed_prompts'])*100:.1f}%")
        logger.info(f"ğŸ—„ï¸ Collection Firestore: polco_magasins_captation")
        logger.info("")
        logger.info("ğŸ‰ Traitement POLCO Captation terminÃ© !")
        
        return True


def main():
    """Point d'entrÃ©e principal."""
    import argparse
    
    parser = argparse.ArgumentParser(description='POLCO Captation - Google Search AvancÃ©')
    parser.add_argument('--test', action='store_true', help='Mode test (1 magasin)')
    parser.add_argument('--limit', type=int, help='Nombre de magasins Ã  traiter')
    parser.add_argument('--store-id', type=str, help='Traiter uniquement le magasin avec cet ID')
    
    args = parser.parse_args()
    
    processor = PolcoCaptationProcessor()
    
    try:
        processor.run(
            limit=args.limit,
            test_mode=args.test,
            store_id=getattr(args, 'store_id', None)
        )
    except KeyboardInterrupt:
        logger.info("\nâ¹ï¸ Processus interrompu")
        sys.exit(0)
    except Exception as e:
        logger.error(f"âŒ Erreur fatale: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
