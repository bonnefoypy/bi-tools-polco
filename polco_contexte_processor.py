#!/usr/bin/env python3
"""
POLCO CONTEXTE PROCESSOR v3 - VERSION STANDARDIS√âE
G√©n√®re une analyse de contexte propre pour les rapports professionnels.
Utilise la classe LLM standardis√©e pour √©viter les erreurs de connexion.
"""

import os
import logging
from typing import Dict, Any, Optional
from datetime import datetime
from polco_llm_client import get_llm_client

# Configuration
PROJECT_ID = "polcoaigeneration-ved6"
REGION = "us-central1"
MODEL_NAME = "gemini-2.5-flash"

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class PolcoContexteProcessorV3:
    """Processeur CONTEXTE v3 pour analyse propre et professionnelle."""
    
    def __init__(self, captation_collection="polco_magasins_captation"):
        self.llm_client = get_llm_client()
        self.polco_fr_content = ""
        self.captation_collection = captation_collection
    

    def init_vertex_ai(self) -> bool:
        """Initialise le client LLM standardis√©."""
        try:
            logger.info(f"üîß Initialisation client LLM standardis√©...")
            logger.info(f"  - Project: {PROJECT_ID}")
            logger.info(f"  - Region: {REGION}")
            logger.info(f"  - Model: {self.llm_client.model_name}")
            
            # Le client LLM est d√©j√† initialis√© dans le constructeur
            logger.info(f"‚úÖ Client LLM standardis√© initialis√© ({self.llm_client.model_name})")
            return True
        except Exception as e:
            logger.error(f"‚ùå Erreur client LLM: {e}")
            return False
    
    def load_polco_fr(self) -> bool:
        """Charge le contenu polcoFR.txt."""
        try:
            with open("polcoFR.txt", 'r', encoding='utf-8') as f:
                self.polco_fr_content = f.read()
            logger.info(f"‚úÖ polcoFR.txt charg√© ({len(self.polco_fr_content)} caract√®res)")
            return True
        except Exception as e:
            logger.error(f"‚ùå Erreur lecture polcoFR.txt: {e}")
            return False
    
    def get_captation_results(self, store_id: str) -> str:
        """R√©cup√®re les r√©sultats de captation depuis la collection configur√©e."""
        try:
            from google.cloud import firestore
            db = firestore.Client(project="polcoaigeneration-ved6")
            doc_ref = db.collection(self.captation_collection).document(f"store_{store_id}")
            doc = doc_ref.get()
            
            if not doc.exists:
                logger.warning(f"‚ö†Ô∏è Aucun r√©sultat de captation trouv√© pour store {store_id}")
                return ""
            
            data = doc.to_dict()
            prompts_results = data.get('prompts_results', {})
            
            if len(prompts_results) < 6:
                logger.warning(f"‚ö†Ô∏è Store {store_id}: seulement {len(prompts_results)}/6 prompts disponibles")
                return ""
            
            # FILTRAGE CIBL√â POUR CONTEXTE : seulement prompts 1, 2, 3
            relevant_prompts = ['prompt_1', 'prompt_2', 'prompt_3', 'prompt_7']
            captation_content = "\n=== DONN√âES PERTINENTES POUR CONTEXTE ===\n"
            
            for prompt_key in relevant_prompts:
                if prompt_key in prompts_results:
                    prompt_data = prompts_results[prompt_key]
                    if prompt_data.get('status') == 'completed' and prompt_data.get('response'):
                        # Limiter chaque prompt √† 10k caract√®res pour √©viter les timeouts
                        response_text = prompt_data['response'][:10000]
                        captation_content += f"\n--- {prompt_key.upper()} (ZONE & CONCURRENCE) ---\n{response_text}\n"
            
            logger.info(f"‚úÖ Store {store_id}: donn√©es contexte r√©cup√©r√©es (prompts 1-3)")
            return captation_content
            
        except Exception as e:
            logger.error(f"‚ùå Erreur r√©cup√©ration captation store {store_id}: {e}")
            return ""
    
    def extract_available_data(self, complete_data: Dict[str, Any]) -> Dict[str, Any]:
        """Extrait uniquement les donn√©es r√©ellement disponibles."""
        
        store_id = complete_data.get('store_id')
        data_sources = complete_data.get('data_sources', {})
        internal_data = data_sources.get('internal_data', {})
        
        # Donn√©es internes
        synthesis = internal_data.get('synthesis_file', {})
        csv_files = internal_data.get('csv_files', {})
        
        # R√©cup√©rer les donn√©es de captation depuis Firestore
        captation_content = self.get_captation_results(store_id)
        
        return {
            'store_id': store_id,
            'synthesis': synthesis.get('content', '') if synthesis else '',
            'captation_content': captation_content,
            'csv_files_count': len(csv_files)
        }
    
    def build_clean_prompt(self, store_id: str, available_data: Dict[str, Any], country: str, language: str) -> str:
        """Construit un prompt propre pour g√©n√©ration de rapport professionnel."""
        
        prompt = f"""Tu es un analyste retail expert. G√©n√®re une analyse de contexte DIRECTEMENT UTILISABLE dans un rapport professionnel.

üåç **LOCALISATION ET ACTUALIT√â OBLIGATOIRES:**

- R√âDIGER ENTI√àREMENT la r√©ponse en {language}
- Adapter l'analyse au contexte √©conomique et culturel du pays {country}

=== INSTRUCTIONS CRITIQUES ===
- NE PAS inclure de formules de politesse ("Voici", "Absolument", etc.)
- NE PAS mentionner de limitations de donn√©es ou fichiers manquants
- NE PAS r√©p√©ter les instructions
- G√©n√©rer UNIQUEMENT le contenu du rapport
- Format Markdown professionnel
- Ton factuel et analytique
- CONSERVER TOUS LES D√âTAILS des donn√©es ultra enhanced (chiffres exacts, noms pr√©cis, adresses, coordonn√©es)
- D√âVELOPPER EXHAUSTIVEMENT plut√¥t que r√©sumer
- INT√âGRER TOUS les √©l√©ments factuels des analyses sectorielles
- ADAPTER le vocabulaire et les r√©f√©rences au contexte {country}
- **PR√âF√âRER LES TABLEAUX** aux listes complexes pour une meilleure lisibilit√© et mise en forme
- Utiliser des tableaux Markdown pour les donn√©es structur√©es (concurrents, m√©triques, comparaisons)
- √âviter les listes √† puces trop longues ou complexes

=== DONN√âES DISPONIBLES ===

Donn√©es Magasin {store_id}:
{available_data.get('synthesis', 'Donn√©es de synth√®se non disponibles')[:15000]}

Analyses Sectorielles:
{available_data.get('captation_content', 'Analyses sectorielles non disponibles')}

=== CONTENU √Ä G√âN√âRER ===

## I. CONTEXTE G√âN√âRAL ET LOCAL

### 1.1 Strat√©gie Nationale Decathlon (Vision 2025-2027)
[D√âVELOPPER EXHAUSTIVEMENT : orientations strat√©giques compl√®tes, ambitions PDM d√©taill√©es avec chiffres exacts, sports prioritaires avec pourcentages, implications directes et chiffr√©es pour le magasin {store_id}]

### 1.2 Profil et Positionnement du Magasin
[D√âVELOPPER EXHAUSTIVEMENT : format magasin avec surface exacte, positionnement national avec rang pr√©cis, CA exact, rentabilit√© par m¬≤, flux d√©taill√©s, r√¥le pr√©cis dans l'√©cosyst√®me Decathlon local/r√©gional]

### 1.3 Zone de Chalandise et Environnement Local
[D√âVELOPPER EXHAUSTIVEMENT : zone de chalandise avec limites pr√©cises, analyse d√©mographique compl√®te (population exacte, CSP d√©taill√©es avec %), √©conomie (revenus exacts, taux ch√¥mage), infrastructures sportives nomm√©es avec adresses, saisonnalit√© chiffr√©e, potentiel touristique quantifi√©]

### 1.4 Analyse Concurrentielle Locale
[D√âVELOPPER EXHAUSTIVEMENT : mapping concurrents avec noms exacts, adresses pr√©cises, distances, forces/faiblesses d√©taill√©es par segment, positionnement prix quantifi√©, opportunit√©s de diff√©renciation factuelles]

### 1.5 Matrice SWOT Approfondie du Magasin
[D√âVELOPPER EXHAUSTIVEMENT : FORCES, FAIBLESSES, OPPORTUNIT√âS, MENACES avec tous les √©l√©ments concrets, chiffres exacts, noms pr√©cis et donn√©es mesurables des analyses sectorielles]

=== G√âN√âRATION ===
G√©n√®re maintenant le contenu complet et professionnel selon cette structure, en te basant UNIQUEMENT sur les donn√©es fournies.
"""
        #logger.info(f"üîç Prompt envoy√© : {prompt}...")
        return prompt
    
    def process_store(self, store_data: Dict[str, Any], country: str, language: str) -> Optional[Dict[str, Any]]:
        """Traite un magasin pour l'analyse contextuelle v3."""
        
        store_id = store_data.get('store_id', 'unknown')
        logger.info(f"üéØ PROCESSEUR CONTEXTE v3 - Magasin {store_id}")
        
        try:
            # Initialiser Vertex AI
            if not self.init_vertex_ai():
                return None
            
            # Charger polcoFR
            if not self.load_polco_fr():
                return None
            
            # Extraire les donn√©es disponibles
            available_data = self.extract_available_data(store_data)

            # Construire le prompt propre
            prompt = self.build_clean_prompt(store_id, available_data, country, language)

            logger.info(f"üìä G√©n√©ration analyse CONTEXTE v3 magasin {store_id}")
            logger.info(f"üìù Prompt contexte: {len(prompt)} caract√®res")
            
            # Diagnostic d√©taill√©
            logger.info(f"üîç Diagnostic prompt store {store_id}:")
            logger.info(f"  - Taille synthesis: {len(available_data.get('synthesis', ''))} chars")  
            logger.info(f"  - Taille captation: {len(available_data.get('captation_content', ''))} chars")
            logger.info(f"  - Model: {self.llm_client.model_name}")

            # G√©n√©rer l'analyse avec le client LLM standardis√©
            start_time = datetime.now()
            
            logger.info(f"üîÑ G√©n√©ration avec client LLM standardis√© pour store {store_id}")
            
            response_text = self.llm_client.generate_simple(
                prompt=prompt,
                max_retries=3,
                temperature=0.1,
                max_tokens=20000
            )
            
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            
            if response_text:
                result_length = len(response_text)
                logger.info(f"‚úÖ Contexte v3 g√©n√©r√©: {result_length} caract√®res en {duration:.1f}s")
                
                return {
                    'section': 'CONTEXTE',
                    'content': response_text,
                    'metadata': {
                        'store_id': store_id,
                        'generation_time': duration,
                        'input_length': len(prompt),
                        'output_length': result_length,
                        'timestamp': datetime.now().isoformat(),
                        'model_used': self.llm_client.model_name,
                        'version': 'v3_standardized'
                    }
                }
            else:
                logger.error(f"‚ùå R√©ponse vide pour {store_id}")
                return None
                
        except Exception as e:
            logger.error(f"‚ùå Erreur traitement contexte v3 {store_id}: {e}")
            return None


    def test_api_simple(self) -> bool:
        """Test simple de l'API avec le client LLM standardis√©."""
        try:
            logger.info("üß™ Test API simple avec client LLM standardis√©...")
            
            simple_prompt = """R√©ponds: Paris, 2.1 millions d'habitants."""

            response_text = self.llm_client.generate_simple(
                prompt=simple_prompt,
                max_retries=3,
                temperature=0.1,
                max_tokens=1000
            )
            
            if response_text:
                logger.info(f"‚úÖ Test API r√©ussi: {len(response_text)} chars")
                logger.info(f"üìù R√©ponse: {response_text[:100]}...")
                return True
            else:
                logger.error("‚ùå Test API √©chou√©: r√©ponse vide")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå Test API √©chou√©: {e}")
            return False

def main():
    """Point d'entr√©e pour test."""
    processor = PolcoContexteProcessorV3()
    logger.info("üéØ Test Processeur CONTEXTE v3 (Version Nettoy√©e)")
    
    # Test d'initialisation
    if not processor.init_vertex_ai():
        logger.error("‚ùå √âchec initialisation Vertex AI")
        return
    
    # Test API simple
    if not processor.test_api_simple():
        logger.error("‚ùå √âchec test API simple")
        return
        
    logger.info("‚úÖ Processeur CONTEXTE v3 op√©rationnel")

if __name__ == "__main__":
    main()
