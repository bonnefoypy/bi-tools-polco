#!/usr/bin/env python3
"""
POLCO ANALYZER 3.0 - Assembleur Final
Fusion intelligente des 4 sections d'analyse en rapport final enrichi
"""

import os
import sys
import re
from datetime import datetime
from typing import Dict, Any, Optional, List
import logging

logging.basicConfig(level=logging.INFO, format='%(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class PolcoFinalAssembler:
    """Assembleur final pour cr√©er le rapport complet."""
    
    def __init__(self):
        """Initialise l'assembleur."""
        pass
    
    def calculate_total_analysis_metrics(self, sections: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Calcule les m√©triques globales de l'analyse."""
        
        metrics = {
            'total_sections': len(sections),
            'total_generation_time': 0,
            'total_input_length': 0,
            'total_output_length': 0,
            'sections_summary': {},
            'processing_timestamp': datetime.now().isoformat()
        }
        
        for section in sections:
            section_name = section.get('section', 'UNKNOWN')
            metrics['total_generation_time'] += section.get('generation_time', 0)
            metrics['total_input_length'] += section.get('input_length', 0)
            metrics['total_output_length'] += section.get('output_length', 0)
            
            metrics['sections_summary'][section_name] = {
                'output_length': section.get('output_length', 0),
                'generation_time': section.get('generation_time', 0),
                'timestamp': section.get('timestamp', 'N/A')
            }
        
        return metrics
    
    def create_executive_summary(self, store_id: str, sections: List[Dict[str, Any]], 
                                complete_data: Dict[str, Any]) -> str:
        """Cr√©e un r√©sum√© ex√©cutif bas√© sur les 4 sections."""
        
        # Extraire quelques m√©triques cl√©s pour le r√©sum√©
        data_sources = complete_data.get('data_sources', {})
        internal_data = data_sources.get('internal_data', {})
        csv_files = internal_data.get('csv_files', {})
        
        # Donn√©es cl√©s
        ca_par_m2_data = csv_files.get('ca_instore_par_m2', {}).get('data', [])
        ca_par_m2 = ca_par_m2_data[0].get('revenue_per_square_meter', 'N/A') if ca_par_m2_data else 'N/A'
        
        classement_data = csv_files.get('classement_national_du_magasin_par_gmv', {}).get('data', [])
        rang_national = classement_data[0].get('national_rank', 'N/A') if classement_data else 'N/A'
        
        surface_data = csv_files.get('surface_de_vente', {}).get('data', [])
        surface = surface_data[0].get('surface_m2', 'N/A') if surface_data else 'N/A'
        
        ca_sports = csv_files.get('ca_par_sport', {}).get('data', [])
        top_sport = ca_sports[0].get('sport_department_label', 'N/A') if ca_sports else 'N/A'
        
        summary = f"""
# R√âSUM√â EX√âCUTIF - ANALYSE POLCO 3.0

## Magasin Decathlon {store_id}

### üìä **M√©triques Cl√©s**
- **Surface commerciale** : {surface} m¬≤
- **CA/m¬≤** : {ca_par_m2}‚Ç¨
- **Rang national** : {rang_national}
- **Sport leader** : {top_sport}

### üéØ **Synth√®se des 5 Analyses Sectorielles**

Cette analyse POLCO 3.0 pr√©sente une approche r√©volutionnaire avec **5 processeurs sp√©cialis√©s** qui ont analys√© en profondeur :

1. **üåç CONTEXTE** : Positionnement strat√©gique et environnement concurrentiel
2. **üë• CIBLES** : Segmentation client et comportements d'achat d√©taill√©s  
3. **üìà POTENTIEL** : Performance quantitative et projections de croissance
4. **üõçÔ∏è OFFRE** : Strat√©gie produits et plans d'action op√©rationnels
5. **üéØ ACTIONS** : Propositions d'actions √† challenger par vos √©quipes

### üîç **Points Saillants Identifi√©s**

*Les points ci-dessous seront extraits automatiquement des 5 sections d'analyse lors de l'impl√©mentation compl√®te.*

### üöÄ **Recommandations Prioritaires**

*Les recommandations transversales seront synth√©tis√©es √† partir des 5 processeurs sp√©cialis√©s.*

---
"""
        return summary
    
    def create_methodology_section(self, metrics: Dict[str, Any]) -> str:
        """Cr√©e la section m√©thodologie."""
        
        methodology = f"""
---

## üî¨ M√âTHODOLOGIE POLCO ANALYZER 3.0

### üèóÔ∏è **Architecture Sectorielle Innovante**

Cette analyse a √©t√© produite par le syst√®me **POLCO ANALYZER 3.0**, premi√®re solution d'analyse retail utilisant une architecture √† **processeurs sp√©cialis√©s** :

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ üìä POLCO ANALYZER 3.0 - Pipeline Sectorielle   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 1Ô∏è‚É£ PROCESSEUR CONTEXTE                         ‚îÇ
‚îÇ    ‚Ä¢ polcoFR.txt + donn√©es d√©mographiques      ‚îÇ
‚îÇ    ‚Ä¢ Zone de chalandise + SWOT approfondi      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 2Ô∏è‚É£ PROCESSEUR CIBLES                           ‚îÇ
‚îÇ    ‚Ä¢ 27 fichiers CSV clients analys√©s          ‚îÇ
‚îÇ    ‚Ä¢ Segmentation comportementale avanc√©e      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 3Ô∏è‚É£ PROCESSEUR POTENTIEL                        ‚îÇ
‚îÇ    ‚Ä¢ M√©triques performance + projections       ‚îÇ
‚îÇ    ‚Ä¢ Analyses quantitatives pouss√©es           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 4Ô∏è‚É£ PROCESSEUR OFFRE                            ‚îÇ
‚îÇ    ‚Ä¢ Classification strat√©gique des sports     ‚îÇ
‚îÇ    ‚Ä¢ Plans d'action op√©rationnels d√©taill√©s    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ üìä G√âN√âRATEUR GRAPHIQUES                        ‚îÇ
‚îÇ    ‚Ä¢ 5+ visualisations automatiques            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ üîß ASSEMBLEUR FINAL                             ‚îÇ
‚îÇ    ‚Ä¢ Fusion intelligente + synth√®se            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### üìà **M√©triques de Traitement**

- **Sections g√©n√©r√©es** : {metrics['total_sections']}
- **Temps total d'analyse** : {metrics['total_generation_time']:.1f} secondes
- **Donn√©es en entr√©e** : {metrics['total_input_length']:,} caract√®res
- **Analyse produite** : {metrics['total_output_length']:,} caract√®res
- **Ratio d'exploitation** : {(metrics['total_output_length'] / max(metrics['total_input_length'], 1) * 100):.1f}%

### üéØ **Performance par Processeur**

"""
        
        for section_name, section_metrics in metrics['sections_summary'].items():
            methodology += f"""
**{section_name}** :
- Analyse g√©n√©r√©e : {section_metrics['output_length']:,} caract√®res
- Temps de traitement : {section_metrics['generation_time']:.1f}s
- Efficacit√© : {(section_metrics['output_length'] / max(section_metrics['generation_time'], 0.1)):.0f} caract√®res/seconde
"""
        
        methodology += f"""

### üîß **Technologies Utilis√©es**

- **IA G√©n√©rative** : Google Gemini 2.5 Pro
- **Donn√©es** : 27+ fichiers CSV + synth√®se magasin + polcoFR.txt + captation externe
- **Visualisations** : Matplotlib + Seaborn (g√©n√©ration automatique)
- **Architecture** : Processeurs parall√©lisables pour analyses sectorielles

### ‚úÖ **Garanties Qualit√©**

- ‚úÖ **Donn√©es r√©elles** : Exploitation de 100% des donn√©es disponibles
- ‚úÖ **Prompts sp√©cialis√©s** : 4 prompts experts de 4000+ mots chacun
- ‚úÖ **Analyses approfondies** : Minimum 3500 mots par section
- ‚úÖ **Visualisations** : Graphiques automatiques int√©gr√©s
- ‚úÖ **Recommandations actionnables** : Plans d'action avec budgets et ROI

---
"""
        return methodology
    
    def fix_section_numbering(self, content: str, chapter_number: int, section_name: str) -> str:
        """Corrige la num√©rotation des sections pour assurer l'ordre logique."""
        
        # Mapping des chapitres
        chapter_titles = {
            1: "I. CONTEXTE G√âN√âRAL ET LOCAL",
            2: "II. √Ä QUI VENDRE (CIBLES CLIENTS)", 
            3: "III. COMBIEN VENDRE (POTENTIEL DE MARCH√â)",
            4: "IV. QUOI VENDRE (OFFRE PRODUIT ET SPORTIVE)",
            5: "V. PROPOSITIONS D'ACTIONS √Ä CHALLENGER PAR VOS √âQUIPES"
        }
        
        # Patterns de remplacement pour corriger la num√©rotation
        wrong_patterns = [
            r"^##?\s*(I{1,4}|[1-4])\.\s*.*$",  # Titles mal num√©rot√©s
            r"^##?\s*II\.\s*√Ä QUI VENDRE.*$",
            r"^##?\s*III\.\s*COMBIEN VENDRE.*$", 
            r"^##?\s*IV\.\s*QUOI VENDRE.*$",
            r"^##?\s*I\.\s*CONTEXTE.*$"
        ]
        
        # Correction sp√©cifique par section
        if section_name == "CONTEXTE":
            # Remplacer toute variation de titre par le bon
            content = re.sub(
                r'^##?\s*(I{1,4}|[1-4])\.\s*CONTEXTE.*$',
                f'## {chapter_titles[1]}',
                content,
                flags=re.MULTILINE | re.IGNORECASE
            )
        elif section_name == "CIBLES":
            content = re.sub(
                r'^##?\s*(I{1,4}|[1-4])\.\s*√Ä QUI VENDRE.*$',
                f'## {chapter_titles[2]}',
                content,
                flags=re.MULTILINE | re.IGNORECASE
            )
        elif section_name == "POTENTIEL":
            content = re.sub(
                r'^##?\s*(I{1,4}|[1-4])\.\s*COMBIEN VENDRE.*$',
                f'## {chapter_titles[3]}',
                content,
                flags=re.MULTILINE | re.IGNORECASE
            )
        elif section_name == "OFFRE":
            content = re.sub(
                r'^##?\s*(I{1,4}|[1-4])\.\s*QUOI VENDRE.*$',
                f'## {chapter_titles[4]}',
                content,
                flags=re.MULTILINE | re.IGNORECASE
            )
        elif section_name == "ACTIONS":
            content = re.sub(
                r'^##?\s*(I{1,5}|[1-5])\.\s*PROPOSITIONS.*$',
                f'## {chapter_titles[5]}',
                content,
                flags=re.MULTILINE | re.IGNORECASE
            )
        
        return content
    
    def clean_section_content(self, content: str, section_name: str) -> str:
        """Nettoie le contenu des sections en supprimant les recommandations et √©l√©ments ind√©sirables."""
        import re
        
        # Supprimer les sections de recommandations des parties I √† IV
        if section_name in ['CONTEXTE', 'CIBLES', 'POTENTIEL', 'OFFRE']:
            # Supprimer les sections avec "Recommandations"
            content = re.sub(
                r'###?\s*\d*\.?\d*\s*[Rr]ecommandations?.*?(?=###?|\Z)',
                '',
                content,
                flags=re.DOTALL | re.IGNORECASE
            )
            
            # Supprimer les sections "Plan d'action"
            content = re.sub(
                r'###?\s*\d*\.?\d*\s*Plan d\'action.*?(?=###?|\Z)',
                '',
                content,
                flags=re.DOTALL | re.IGNORECASE
            )
            
            # Supprimer les sections "Actions" ou "Propositions"
            content = re.sub(
                r'###?\s*\d*\.?\d*\s*[Aa]ctions?.*?(?=###?|\Z)',
                '',
                content,
                flags=re.DOTALL | re.IGNORECASE
            )
            
            content = re.sub(
                r'###?\s*\d*\.?\d*\s*[Pp]ropositions?.*?(?=###?|\Z)',
                '',
                content,
                flags=re.DOTALL | re.IGNORECASE
            )
        
        # Nettoyer les lignes vides multiples
        content = re.sub(r'\n\s*\n\s*\n+', '\n\n', content)
        
        return content.strip()
    
    def assemble_final_report(self, store_id: str, sections: List[Dict[str, Any]], 
                             complete_data: Dict[str, Any], 
                             chart_integration: str = "") -> Dict[str, Any]:
        """Assemble le rapport final complet."""
        
        logger.info(f"üîß Assemblage rapport final magasin {store_id}")
        
        # Calculer les m√©triques
        metrics = self.calculate_total_analysis_metrics(sections)
        
        # Cr√©er les sections du rapport
        executive_summary = self.create_executive_summary(store_id, sections, complete_data)
        methodology = self.create_methodology_section(metrics)
        
        # Assembler le contenu principal dans l'ordre logique
        section_order = ['CONTEXTE', 'CIBLES', 'POTENTIEL', 'OFFRE', 'ACTIONS']
        main_content = ""
        
        # Cr√©er un dictionnaire pour acc√®s rapide
        sections_dict = {section.get('section', ''): section for section in sections}
        
        for i, section_name in enumerate(section_order, 1):
            if section_name in sections_dict:
                section = sections_dict[section_name]
                section_content = section.get('content', '')
                
                # S'assurer que la num√©rotation est correcte
                if section_content:
                    # Nettoyer le contenu (supprimer les recommandations des sections I-IV)
                    cleaned_content = self.clean_section_content(section_content, section_name)
                    
                    # Remplacer les num√©rotations incorrectes par la bonne
                    section_content = self.fix_section_numbering(cleaned_content, i, section_name)
                    
                    main_content += f"""

---

{section_content}

"""
            else:
                logger.warning(f"‚ö†Ô∏è Section {section_name} manquante dans l'analyse")
        
        # Ajouter les sections non pr√©vues √† la fin
        processed_sections = set(section_order)
        for section in sections:
            section_name = section.get('section', '')
            if section_name not in processed_sections and section_name:
                section_content = section.get('content', '')
                main_content += f"""

---

### Section Additionnelle: {section_name}

{section_content}

"""
        
        # Int√©grer les graphiques si disponibles
        graphics_section = ""
        if chart_integration:
            graphics_section = chart_integration
        
        # Assembler le rapport complet (sans partie technique/m√©thodologie)
        final_report_content = f"""{executive_summary}

{main_content}

{graphics_section}
"""
        
        # Pr√©parer le r√©sultat final
        final_report = {
            'store_id': store_id,
            'report_content': final_report_content,
            'metrics': metrics,
            'sections_processed': [s.get('section') for s in sections],
            'total_length': len(final_report_content),
            'generation_timestamp': datetime.now().isoformat(),
            'analyzer_version': '3.0_sectorial'
        }
        
        logger.info(f"‚úÖ Rapport final assembl√©: {len(final_report_content):,} caract√®res")
        logger.info(f"üìä Sections int√©gr√©es: {', '.join(final_report['sections_processed'])}")
        
        return final_report
    
    def save_final_report_to_firestore(self, final_report: Dict[str, Any], 
                                      db, collection_name: str = "polco_analyzer_3_0") -> bool:
        """Sauvegarde le rapport final dans Firestore."""
        
        try:
            store_id = final_report['store_id']
            doc_ref = db.collection(collection_name).document(f"analyzer_3_0_{store_id}")
            doc_ref.set(final_report)
            
            logger.info(f"‚úÖ Rapport final sauvegard√©: analyzer_3_0_{store_id}")
            return True
        except Exception as e:
            logger.error(f"‚ùå Erreur sauvegarde rapport final: {e}")
            return False


def main():
    """Test de l'assembleur final."""
    pass


if __name__ == "__main__":
    main()
